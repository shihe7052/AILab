{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 假設你的檔案在 /MyDrive/datasets/celeba.zip\n",
        "!unzip \"/content/drive/MyDrive/img_align_celeba.zip\" -d \"/content/datasets/celeba\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEgjcqy6ZCBH",
        "outputId": "7e4677ae-c0fa-446c-863d-543ac0acd43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Archive:  /content/drive/MyDrive/img_align_celeba.zip\n",
            "checkdir:  cannot create extraction directory: /content/datasets/celeba\n",
            "           No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 0. 基本設定（掛載雲端、解壓、資料集路徑） ====\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 掛載雲端\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/img_align_celeba.zip\"  # 你的 zip 檔路徑\n",
        "EXTRACT_DIR = \"/content/datasets/celeba/img_align_celeba\" # 解壓後圖片所在資料夾\n",
        "SAMPLES_DIR = \"/content/drive/MyDrive/celeba_gan_samples\" # 生成結果輸出資料夾\n",
        "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
        "\n",
        "# 解壓（若尚未解壓才會執行）\n",
        "if not os.path.exists(EXTRACT_DIR):\n",
        "    os.makedirs(os.path.dirname(EXTRACT_DIR), exist_ok=True)\n",
        "    !unzip -q \"{ZIP_PATH}\" -d \"/content/datasets/celeba\"\n",
        "else:\n",
        "    print(\"🚀 已找到解壓後資料夾，略過解壓。\")\n",
        "\n",
        "# 檢查前幾個檔案\n",
        "!ls -l \"/content/datasets/celeba\" | head -n 20\n",
        "!ls -l \"{EXTRACT_DIR}\" | head -n 10\n",
        "\n",
        "# ==== 1. 匯入套件 ====\n",
        "import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ==== 2. 自訂平面影像資料集（無類別資料夾也可讀） ====\n",
        "class FlatImageFolder(Dataset):\n",
        "    def __init__(self, root, transform=None, exts=(\"jpg\",\"jpeg\",\"png\",\"bmp\",\"webp\")):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        files = []\n",
        "        for ext in exts:\n",
        "            files.extend(glob.glob(os.path.join(root, f\"**/*.{ext}\"), recursive=True))\n",
        "            files.extend(glob.glob(os.path.join(root, f\"*.{ext}\")))\n",
        "        self.files = sorted(list(set(files)))\n",
        "        if len(self.files) == 0:\n",
        "            raise RuntimeError(f\"No images found under: {root}\")\n",
        "        print(f\"🖼️  找到 {len(self.files)} 張影像（於 {root}）\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.files[idx]\n",
        "        img = Image.open(fp).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        # 這裡不需要 label，回傳 dummy 0\n",
        "        return img, 0\n",
        "\n",
        "# ==== 3. 參數與資料載入 ====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"🖥️  Device:\", device)\n",
        "\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "nz = 100     # latent dim\n",
        "ngf = 64     # G base channels\n",
        "ndf = 64     # D base channels\n",
        "epochs = 5   # 示範\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "dataset = FlatImageFolder(EXTRACT_DIR, transform=transform)\n",
        "dataloader = DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True,\n",
        "    num_workers=2, pin_memory=(device.type==\"cuda\")\n",
        ")\n",
        "\n",
        "# ==== 4. DCGAN 模型（D 無 Sigmoid，配 BCEWithLogitsLoss） ====\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=100, ngf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),  # 1x1 -> 4x4\n",
        "            nn.BatchNorm2d(ngf*8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),  # 4x4 -> 8x8\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),  # 8x8 -> 16x16\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),    # 16x16 -> 32x32\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),       # 32x32 -> 64x64\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        return self.main(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),      # 64->32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),   # 32->16\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False), # 16->8\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False), # 8->4\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False)      # 4->1\n",
        "            # 無 Sigmoid\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x).view(-1)\n",
        "\n",
        "netG = Generator(nz, ngf).to(device)\n",
        "netD = Discriminator(ndf).to(device)\n",
        "\n",
        "# 權重初始化（DCGAN 建議 N(0, 0.02)）\n",
        "def weights_init(m):\n",
        "    cname = m.__class__.__name__\n",
        "    if cname.find('Conv') != -1 or cname.find('Linear') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    if cname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.zeros_(m.bias.data)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "# 固定噪聲，追蹤訓練進度\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# ==== 5. 訓練 ====\n",
        "netG.train(); netD.train()\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    for i, (real, _) in enumerate(dataloader):\n",
        "        real = real.to(device)\n",
        "        bsz = real.size(0)\n",
        "\n",
        "        # 標籤（可採 label smoothing：真實=0.9）\n",
        "        real_labels = torch.full((bsz,), 0.9, device=device)\n",
        "        fake_labels = torch.zeros(bsz, device=device)\n",
        "\n",
        "        # ---- 更新 D ----\n",
        "        optimizerD.zero_grad()\n",
        "        pred_real = netD(real)\n",
        "        lossD_real = criterion(pred_real, real_labels)\n",
        "\n",
        "        noise = torch.randn(bsz, nz, 1, 1, device=device)\n",
        "        fake = netG(noise).detach()\n",
        "        pred_fake = netD(fake)\n",
        "        lossD_fake = criterion(pred_fake, fake_labels)\n",
        "\n",
        "        lossD = lossD_real + lossD_fake\n",
        "        lossD.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        # ---- 更新 G ----\n",
        "        optimizerG.zero_grad()\n",
        "        noise = torch.randn(bsz, nz, 1, 1, device=device)\n",
        "        gen = netG(noise)\n",
        "        pred = netD(gen)\n",
        "        lossG = criterion(pred, torch.ones(bsz, device=device))\n",
        "        lossG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "    print(f\"[Epoch {epoch}/{epochs}]  LossD: {lossD.item():.4f}  LossG: {lossG.item():.4f}\")\n",
        "\n",
        "    # 以固定噪聲匯出觀察圖\n",
        "    netG.eval()\n",
        "    with torch.no_grad():\n",
        "        samples = netG(fixed_noise).cpu()\n",
        "        save_path = os.path.join(SAMPLES_DIR, f\"epoch_{epoch:03d}.png\")\n",
        "        save_image(samples, save_path, normalize=True, value_range=(-1, 1), nrow=8)\n",
        "        print(\"💾 Saved:\", save_path)\n",
        "    netG.train()\n",
        "\n",
        "    # （可選）儲存 ckpt\n",
        "    torch.save({\n",
        "        \"G\": netG.state_dict(),\n",
        "        \"D\": netD.state_dict(),\n",
        "        \"optG\": optimizerG.state_dict(),\n",
        "        \"optD\": optimizerD.state_dict(),\n",
        "        \"epoch\": epoch\n",
        "    }, os.path.join(SAMPLES_DIR, f\"ckpt_{epoch:03d}.pt\"))\n",
        "\n",
        "print(\"✅ 訓練完成！檔案已輸出到：\", SAMPLES_DIR)\n",
        "\n",
        "# ==== 6. 產生一批新的人臉樣本（收尾） ====\n",
        "netG.eval()\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(64, nz, 1, 1, device=device)\n",
        "    gen_samples = netG(z).cpu()\n",
        "    save_image(gen_samples, os.path.join(SAMPLES_DIR, \"final_samples.png\"),\n",
        "               normalize=True, value_range=(-1, 1), nrow=8)\n",
        "print(\"📷 另存一批最終樣本：final_samples.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsV2lWXMbyOf",
        "outputId": "522f319b-4033-4ac9-df07-cd1242011ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "total 5772\n",
            "drwxr-xr-x 2 root root 5906432 Sep 28  2015 img_align_celeba\n",
            "total 1737936\n",
            "-rw-r--r-- 1 root root 11440 Sep 28  2015 000001.jpg\n",
            "-rw-r--r-- 1 root root  7448 Sep 28  2015 000002.jpg\n",
            "-rw-r--r-- 1 root root  4253 Sep 28  2015 000003.jpg\n",
            "-rw-r--r-- 1 root root 10747 Sep 28  2015 000004.jpg\n",
            "-rw-r--r-- 1 root root  6351 Sep 28  2015 000005.jpg\n",
            "-rw-r--r-- 1 root root  8073 Sep 28  2015 000006.jpg\n",
            "-rw-r--r-- 1 root root  8203 Sep 28  2015 000007.jpg\n",
            "-rw-r--r-- 1 root root  7725 Sep 28  2015 000008.jpg\n",
            "-rw-r--r-- 1 root root  8641 Sep 28  2015 000009.jpg\n",
            "🖥️  Device: cuda\n",
            "🖼️  找到 202599 張影像（於 /content/datasets/celeba/img_align_celeba）\n",
            "[Epoch 1/5]  LossD: 0.6953  LossG: 4.3539\n",
            "💾 Saved: /content/drive/MyDrive/celeba_gan_samples/epoch_001.png\n",
            "[Epoch 2/5]  LossD: 1.2970  LossG: 1.0415\n",
            "💾 Saved: /content/drive/MyDrive/celeba_gan_samples/epoch_002.png\n",
            "[Epoch 3/5]  LossD: 0.8110  LossG: 2.1476\n",
            "💾 Saved: /content/drive/MyDrive/celeba_gan_samples/epoch_003.png\n",
            "[Epoch 4/5]  LossD: 1.0071  LossG: 2.9464\n",
            "💾 Saved: /content/drive/MyDrive/celeba_gan_samples/epoch_004.png\n",
            "[Epoch 5/5]  LossD: 1.4452  LossG: 3.6145\n",
            "💾 Saved: /content/drive/MyDrive/celeba_gan_samples/epoch_005.png\n",
            "✅ 訓練完成！檔案已輸出到： /content/drive/MyDrive/celeba_gan_samples\n",
            "📷 另存一批最終樣本：final_samples.png\n"
          ]
        }
      ]
    }
  ]
}